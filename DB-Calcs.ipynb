{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the pandas library for managing data \n",
    "#\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set the notebook so that it can display all countries in a dataframe\n",
    "#\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define variables for reading in the data worksheet from the World Bank's Doing Business website\n",
    "#\n",
    "data_url = 'http://www.doingbusiness.org/~/media/WBG/DoingBusiness/Documents/Data/DB18-Historical-data-complete-data-with-DTFs.xlsx'\n",
    "sheet = \"All Data\"\n",
    "header_row = 1 # the convention in Python is 0-based indexes; in the worksheet the header is in row 2 \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the data sheet into a pandas dataframe df\n",
    "# Use the header to get variable / column names \n",
    "# Convert the value 'No Practice' to NaN - not a number \n",
    "# \n",
    "df = pd.read_excel(data_url,sheet_name = sheet, header = header_row, na_values = ['No Practice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove the #-delimiter on the line below, to see rows that include Bangladesh\n",
    "#\n",
    "#df[150:200]\n",
    "#\n",
    "# It is one of the countries where a second city was added. It is because of these additions \n",
    "#    that later there is a cell that drops rows if \n",
    "# \n",
    "#       \"len(df2.loc[i,'code']) != 3\"\n",
    "#  \n",
    "#    that is, if the code has more or less characters than the 3-letters that were used for the original observations\n",
    "#    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary with keys that are the existing variable names and values that are the new names I use\n",
    "# \n",
    "# Note that the import from the excel sheet includes some random line break characters '\\n'\n",
    "#\n",
    "rename_variables = {'Country code': 'code', \n",
    "                    'DB Year': 'year', \n",
    "                    'Procedures - Men (number) ': 's_procs',\n",
    "                    'Time - Men (days)': 's_time', \n",
    "                    'Cost - Men (% of income per capita)': 's_cost', \n",
    "                    'Minimum capital (% of income per capita)': 's_min_cap', \n",
    "                    'Procedures (number)': 'cn_procs', 'Time (days)': 'cn_time', \n",
    "                    'Cost (% of Warehouse value)': 'cn_cost', \n",
    "                    'Procedures (number).1': 'e_procs', \n",
    "                    'Time (days).1': 'e_time', \n",
    "                    'Cost (% of income per capita)': 'e_cost', \n",
    "                    'Procedures (number).2': 'rp_procs', \n",
    "                    'Time (days).2': 'rp_time', \n",
    "                    'Cost (% of property value)': 'rp_cost', \n",
    "                    'Strength of legal rights index (0-12) (DB15-18 methodology) ': 'ct_s', \n",
    "                    'Depth of credit information index (0-8) (DB15-18 methodology) ': 'ct_d', \n",
    "                    'Extent of conflict of interest regulation index (0-10)\\n(DB15-18 methodology) ':'pm_cft', \n",
    "                    'Extent of shareholder governance index (0-10) (DB15-18 methodology) ':'pm_gv', \n",
    "                    'Payments (number per year)': 't_p', 'Time (hours per year)': \n",
    "                    't_t', 'Total tax rate (% of profit)': 't_tr', \n",
    "                    'Time (days).3': 'en_time', \n",
    "                    'Cost (% of claim)': 'en_cost', \n",
    "                    'Recovery rate (cents on the dollar)': 'ri_r', \n",
    "                    'Strength of insolvency framework index (0-16) (DB15-18 methodology)': 'ri_s'\n",
    "                   }\n",
    "\n",
    "# Treat the variable names as a set so that set subtraction specifies the one to drop\n",
    "#\n",
    "all_vars = set(df.columns.values)\n",
    "\n",
    "# Old_names from for the variables that the code keeps and renames \n",
    "old_names = set(rename_variables.keys())\n",
    "\n",
    "# The implied set of variables to drop\n",
    "vars_to_drop = all_vars - old_names\n",
    "\n",
    "# Create a list with the new names for the variables that remain \n",
    "new_names = list(rename_variables.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an independent copy of the dataframe.\n",
    "#\n",
    "# If I want to redo my calculations as I work interactively, I can just re-execute this cell without \n",
    "#     reloading the data from the external website\n",
    "# \n",
    "df2 = pd.DataFrame(df.copy(deep = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert the set of variables that I will drop from a set to a list \n",
    "#\n",
    "el_2 = list(vars_to_drop)\n",
    "#\n",
    "#len(df2.columns.values) # count of variables before the drop \n",
    "#\n",
    "# Drop the variables \n",
    "#\n",
    "df2.drop(el_2, axis = 1, inplace = True)\n",
    "#\n",
    "#len(df2.columns.values) # to check the variable count after the drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Rename the columns / variables that remain  \n",
    "#\n",
    "df2.rename(columns=rename_variables, inplace = True)\n",
    "#\n",
    "# To verify that rename and drop affects df2 but not df, uncomment one, then other of next two lines and compare \n",
    "#df\n",
    "#df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop years before and including 2013 \n",
    "#\n",
    "df2.drop(labels = [i for i in df2.index if df2.loc[i,'year'] <= 2013], inplace = True)\n",
    "#\n",
    "#len(df2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As noted above, drop recently added extra cities  \n",
    "# \n",
    "df2.drop(labels = [i for i in df2.index if len(df2.loc[i,'code']) != 3], inplace = True)\n",
    "#\n",
    "#len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify a multi-index for the remaining variables \n",
    "# \n",
    "df2.set_index(['year', 'code'], inplace=True)\n",
    "#\n",
    "#df2 # inspect results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a separate dataframe to store the normalized or distance to the frontier (DTF) values \n",
    "#    for different indicators. \n",
    "#\n",
    "dtf = pd.DataFrame(df2.copy(deep = True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list of all the indicators that remain \n",
    "\n",
    "el_3 = list(dtf.columns.values)\n",
    "#el_3\n",
    "#\n",
    "#len(el_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Indicators in high are ones where bigger values are better; opposite for variables in low \n",
    "#\n",
    "high = ['ct_s', 'ct_d', 'pm_cft', 'pm_gv',  'ri_r', 'ri_s' ]\n",
    "low = ['s_procs', 's_time', 's_cost', 's_min_cap', 'cn_procs', 'cn_time',\n",
    "       'cn_cost', 'e_procs', 'e_time', 'e_cost', 'rp_procs', 'rp_time',  \n",
    "       'rp_cost', 't_p', 't_t', 't_tr', 'en_time', 'en_cost']\n",
    "#\n",
    "# len(high) + len(low) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This loop calculates the distance to the frontier for the 24 variables that are available in a consistent  \n",
    "#    form for the years I consider, DB2014-18, or calendar 2013-17. \n",
    "# \n",
    "# These normalized values are stored in the dtf dataframe. The raw values remainin in the df2 dataframe. \n",
    "#\n",
    "# The loop defines the distance to the frontier by taking the biggest and smallest values for \n",
    "#    each variable in any year from DB years 2014-18. \n",
    "#\n",
    "# I wrote the code as I did assuming that I would use the max and min in each year; then I found \n",
    "#    that they change over time, sometimes substantially. This is the type of issue that I understand only \n",
    "#    if I work directly with the data myself. \n",
    "#\n",
    "# This problem is that the min (worst) value for an indicator can change dramatically based on \n",
    "#    what happens in a single country with a very bad business environment. \n",
    "#    So I added the two lines that calculate mn_m and mx_m by taking the min and\n",
    "#    max over all DB years from 2014 to 2018. This decision influences the relative influence that \n",
    "#    different indicators have in my results.  \n",
    "#\n",
    "# This is an important point. Suppose that it takes every other country between 10 and 100 days to \n",
    "#    to issue a permit, but in one laggard it takes 10,000 days. Then all other countries will have a DTF \n",
    "#    score for this indicator in the range 10/10,000 to 100/10,000. In this case, a country that takes only \n",
    "#    10 days gets almost no recognition for its better performance relative to a country that takes 100. \n",
    "#\n",
    "# The DTF value for this permit indicator will be 0.999 for the country that takes 10 days \n",
    "#    and 0.990 for the country that takes 100 days. When this indicator is averaged along with 8 or 9 others, \n",
    "#    it will have an effect on the overall indicator that is visible only in the third decimal place. It will \n",
    "#    be swamped by variation in other indicators. \n",
    "#\n",
    "# My choice is not one that I would defend as being the right way to determine the relative influence of \n",
    "#    different indicators. It underweights indicators with a fat lower (that is worse) tail. I haven't explored \n",
    "#    the sensitivity of the results for Chile to alternative choices because I didn't want to be accused of \n",
    "#    manipulating the data to get some particular outcome. \n",
    "#\n",
    "# For my purpose, the choice I made had the advantage that it is arbitrary and leads to rankings for \n",
    "#    countries that do not change from year to year because of year to year **changes** in the min (worst) \n",
    "#    value of an indicator in some lagging country. My choice ensures that he range from best to worst, \n",
    "#    and hence the relative influence of each indicator, stays fixed over all the years that I consider. \n",
    "#\n",
    "# One of the advantages of making this code available is that it lets others do their own sensitivity analysis\n",
    "#    with respect to this or any other issue. \n",
    "#\n",
    "# The approach used by the Doing Business team addresses this concern in a different way. \n",
    "#    For most indicators (but not all), they also take the min and max over a five year interval.\n",
    "#    See the description of their approach here: \n",
    "#\n",
    "#     http://www.doingbusiness.org/~/media/WBG/DoingBusiness/Documents/Annual-Reports/English/DB18-Chapters/DB18-DTF-and-DBRankings.pdf\n",
    "#\n",
    "# To view the values for the min and max for each variable over all years or year by year, uncomment the \n",
    "#    print statements in this loop.  \n",
    "# \n",
    "# \n",
    "\n",
    "for i in range(len(el_3)):\n",
    "    mn = df2.groupby(['year'])[el_3[i]].min()\n",
    "    #print ('mn = ', mn)\n",
    "    mn_m = mn.min()\n",
    "    #print('mn_m ',mn_m)\n",
    "    mx = df2.groupby(['year'])[el_3[i]].max()\n",
    "    #print ('mx = ', mx)\n",
    "    mx_m = mx.max()\n",
    "    #print('mx_m ',mx_m)\n",
    "    if el_3[i] in low:\n",
    "        dtf[el_3[i]] = (mx_m - df2[el_3[i]]) / (mx_m - mn_m)\n",
    "    else:\n",
    "        dtf[el_3[i]] = (df2[el_3[i]] - mn_m)  / (mx_m - mn_m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2[4:5]  # Test raw data for visual comparison with Bank numbers from spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dtf[4:5]  # Test dtf or normalized data for comparison with Bank numbers on Afghanistan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Follow the Bank's hierarchical procedure; average the sub-components of the different indicators\n",
    "# \n",
    "# d_ => prefix that means \"distance to ...\"\n",
    "# s => Starting A Business ...\n",
    "# cn => Construction Permits \n",
    "# e => Getting Electricity \n",
    "# rp => Registering Property \n",
    "# ct => Contract Enforcement \n",
    "# pm => Protection for Minority investors\n",
    "# t => Taxes\n",
    "# en => Enforcing Contracts \n",
    "# ri => Resolving Insolvencies \n",
    "d_s = pd.Series((dtf['s_procs'] + dtf['s_time'] + dtf['s_cost'] + dtf['s_min_cap']) / 4)\n",
    "d_cn = pd.Series((dtf['cn_procs'] + dtf['cn_time'] +  dtf['cn_cost']) / 3)\n",
    "d_e = pd.Series((dtf['e_procs'] + dtf['e_time'] + dtf['e_cost']) / 3)\n",
    "d_rp = pd.Series((dtf['rp_procs'] + dtf['rp_time'] + dtf['rp_cost']) / 3)\n",
    "d_ct = pd.Series((dtf['ct_s'] + dtf['ct_d']) / 2) \n",
    "d_pm = pd.Series((dtf['pm_cft'] + dtf['pm_gv']) / 2)\n",
    "d_t = pd.Series((dtf['t_p'] + dtf['t_t'] + dtf['t_tr']) / 3)\n",
    "d_en = pd.Series((dtf['en_time'] + dtf['en_cost']) / 2)\n",
    "d_ri = pd.Series((dtf['ri_r'] + dtf['ri_s']) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The overall average across indicators \n",
    "# I have 9 here because none of the indicators of trade costs are available for all 5 years \n",
    "# It should be easy to tweak the code to include some of the trade indicators but \n",
    "#     at the cost of restricting the analysis to the 4 data years 2014 to 2017 \n",
    "#\n",
    "d_DTF = pd.Series((d_s + d_cn + d_e + d_rp + d_ct + d_pm + d_t + d_en + d_ri) / 9)\n",
    "#d_DTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([df2, d_s.rename('s'), \n",
    "                 d_cn.rename('cn'), \n",
    "                 d_e.rename('e'), \n",
    "                 d_rp.rename('rp'), \n",
    "                 d_ct.rename('ct'), \n",
    "                 d_pm.rename('pm'), \n",
    "                 d_t.rename('t'), \n",
    "                 d_en.rename('en'), \n",
    "                 d_ri.rename('ri'), \n",
    "                 d_DTF.rename('DTF')], axis=1)\n",
    "#df2\n",
    "#len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.dropna(axis = 0, subset = ['DTF'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df2\n",
    "#len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define 5 series, one for each year, indexed by country code\n",
    "#\n",
    "d_2018 = pd.Series(df2.loc[2018]['DTF'])\n",
    "#len(d_2018)\n",
    "d_2017 = pd.Series(df2.loc[2017]['DTF'])\n",
    "#len(d_2017)\n",
    "d_2016 = pd.Series(df2.loc[2016]['DTF'])\n",
    "#len(d_2016)\n",
    "d_2015 = pd.Series(df2.loc[2015]['DTF'])\n",
    "#len(d_2015)\n",
    "d_2014 = pd.Series(df2.loc[2014]['DTF'])\n",
    "#len(d_2014)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create series objects that I can sort, one for each year\n",
    "# \n",
    "df_2018 = pd.DataFrame(d_2018)\n",
    "dfs_2018 = df_2018.sort_values(by =['DTF'], axis=0, ascending=False, inplace=False, kind='quicksort')\n",
    "length=len(dfs_2018)\n",
    "dfs_2018['Rank18']= pd.Series(range(1, length + 1 ,1), index=dfs_2018.index)\n",
    "\n",
    "df_2017 = pd.DataFrame(d_2017)\n",
    "dfs_2017 = df_2017.sort_values(by =['DTF'], axis=0, ascending=False, inplace=False, kind='quicksort')\n",
    "length=len(dfs_2017)\n",
    "dfs_2017['Rank17']= pd.Series(range(1, length + 1 ,1), index=dfs_2017.index)\n",
    "\n",
    "df_2016 = pd.DataFrame(d_2016)\n",
    "dfs_2016 = df_2016.sort_values(by =['DTF'], axis=0, ascending=False, inplace=False, kind='quicksort')\n",
    "length=len(dfs_2016)\n",
    "dfs_2016['Rank16']= pd.Series(range(1, length + 1 ,1), index=dfs_2016.index)\n",
    "\n",
    "df_2015 = pd.DataFrame(d_2015)\n",
    "dfs_2015 = df_2015.sort_values(by =['DTF'], axis=0, ascending=False, inplace=False, kind='quicksort')\n",
    "length=len(dfs_2015)\n",
    "dfs_2015['Rank15']= pd.Series(range(1, length + 1 ,1), index=dfs_2015.index)\n",
    "\n",
    "df_2014 = pd.DataFrame(d_2014)\n",
    "dfs_2014 = df_2014.sort_values(by =['DTF'], axis=0, ascending=False, inplace=False, kind='quicksort')\n",
    "length=len(dfs_2014)\n",
    "dfs_2014['Rank14']= pd.Series(range(1, length + 1 ,1), index=dfs_2014.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new dataframe object dfs indexed by country code that holds sorted series  \n",
    "#\n",
    "# Combine the sorted series into a single dataframe indexed by country \n",
    "#\n",
    "dfs_all = pd.concat([dfs_2014, dfs_2015, dfs_2016, dfs_2017,dfs_2018], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTF        0.768501\n",
       "Rank14    46.000000\n",
       "DTF        0.768808\n",
       "Rank15    46.000000\n",
       "DTF        0.776713\n",
       "Rank16    49.000000\n",
       "DTF        0.778045\n",
       "Rank17    48.000000\n",
       "DTF        0.782235\n",
       "Rank18    51.000000\n",
       "Name: CHL, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the data for the row of dfs_all that has the results for Chile\n",
    "#\n",
    "dfs_all.loc['CHL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
